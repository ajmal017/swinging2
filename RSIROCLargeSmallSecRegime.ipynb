{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "\n",
    "def prep_regime_filter(regime_df, roc_col_name='regime_roc', mv_col_name='regime_ma',\n",
    "                       close_name='regime_close',\n",
    "                       ma_period=200,\n",
    "                       roc_period=45):\n",
    "    regime_df.loc[:, roc_col_name] = ta.momentum.ROCIndicator(regime_df.close_adj, n=roc_period).roc()\n",
    "    regime_df.loc[:, mv_col_name] = regime_df.set_index(\n",
    "        'date'\n",
    "    ).close_adj.rolling('%dd' % ma_period, min_periods=1).mean().values\n",
    "    regime_df.loc[:, close_name] = regime_df.close_adj\n",
    "    return regime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "Market = collections.namedtuple('Market', 'candle_data market_index sec_index')\n",
    "\n",
    "market_metadata = {\n",
    "    600: Market(candle_data='historical_pr_data_600_sec.parquet',\n",
    "                market_index='S_and_P_600_index.parquet',\n",
    "                sec_index='sector_index_1000.parquet'),\n",
    "    400: Market(candle_data='historical_pr_data_400_sec.parquet',\n",
    "                market_index='S_and_P_400_index.parquet',\n",
    "                sec_index='sector_index_400.parquet'),\n",
    "    500: Market(candle_data='historical_pr_data_sec.parquet',\n",
    "                market_index='S_and_P_index.parquet',\n",
    "                sec_index='sector_index.parquet')\n",
    "}\n",
    "\n",
    "candle_dfs = {\n",
    "    x: pd.read_parquet(market_metadata[x].candle_data)\n",
    "    for x in market_metadata\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_index_dfs = {\n",
    "    x: pd.read_parquet(market_metadata[x].market_index)\n",
    "    for x in market_metadata\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_index_dfs = {\n",
    "    x: pd.read_parquet(market_metadata[x].sec_index)\n",
    "    for x in market_metadata\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_market_regimes_dfs = {\n",
    "    x: prep_regime_filter(market_index_dfs[x])\n",
    "    for x in market_index_dfs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sector_regime_dfs = {\n",
    "    x: sector_index_dfs[x].groupby('sector').apply(lambda x: prep_regime_filter(x, roc_col_name='sector_roc',\n",
    "                                                                     mv_col_name='sector_ma',\n",
    "                                                                     close_name='sector_close'))\n",
    "    for x in sector_index_dfs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_w_regime = {\n",
    "    x: candle_dfs[x].merge(prep_market_regimes_dfs[x][['date', 'regime_roc', 'regime_close', 'regime_ma']],\n",
    "                           on='date', how='left')\n",
    "    for x in candle_dfs\n",
    "}\n",
    "candle_w_regime = {\n",
    "    x: candle_w_regime[x].merge(prep_sector_regime_dfs[x][['date', 'sector', 'sector_roc', 'sector_close', 'sector_ma']],\n",
    "                                on=['date', 'sector'], how='left')\n",
    "    for x in candle_w_regime\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.concat((candle_w_regime[x] for x in candle_w_regime), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.drop_duplicates(subset=['date', 'symbol']).sort_values(['symbol', 'date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "import numpy as np\n",
    "\n",
    "def mean_atr(df, atr_period=14):\n",
    "    df.loc[:, 'last_close'] = df.close_adj.shift(1)\n",
    "    atr_high = np.maximum(df.high_adj, df.last_close)\n",
    "    atr_low = np.minimum(df.high_adj, df.last_close)\n",
    "    atr = atr_high - atr_low\n",
    "    return atr, atr.ewm(span=atr_period, adjust=False).mean()\n",
    "\n",
    "def get_volatility(df, volatility_period=14):\n",
    "    volatility = (df.close_adj.diff() / df.close_adj.shift(1)).abs().ewm(span=volatility_period,\n",
    "                                                                         adjust=False).mean().values\n",
    "    return volatility\n",
    "\n",
    "def get_indicators(sym_df, rsi_period=7, roc_period=60, ma_period=200, volatility_period=14):\n",
    "    rsi = ta.momentum.RSIIndicator(close=sym_df.close_adj, n=rsi_period).rsi()\n",
    "    sym_df.loc[:, 'rsi'] = rsi\n",
    "    sym_df.loc[:, 'roc'] = ta.momentum.ROCIndicator(sym_df.close_adj, n=roc_period).roc()\n",
    "    sym_df.loc[:, 'mv_avg'] = sym_df.set_index(\n",
    "        'date'\n",
    "    ).close_adj.rolling('%dd' % ma_period, min_periods=1).mean().values\n",
    "    sym_df.loc[:, 'mean_atr'] = mean_atr(sym_df)[1].values\n",
    "    sym_df.loc[:, 'volatility'] = get_volatility(sym_df, volatility_period=volatility_period)\n",
    "    return sym_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df_norm.reset_index(drop=True).groupby('symbol').apply(get_indicators).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_index = df_ind.regime_roc.notnull() & df_ind.sector_roc.isnull()\n",
    "df_ind.loc[bool_index, 'sector_roc'] = df_ind.loc[bool_index, 'regime_roc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entrances(df,\n",
    "                  rsi_oversold=30,\n",
    "                  roc_change=0,\n",
    "                  regime_roc_change=0):\n",
    "    df.loc[:, 'last_rsi'] = df.rsi.shift(1)\n",
    "    df.loc[:, 'rsi_oversold_enter'] = 0\n",
    "    df.loc[:, 'rsi_roc'] = df.rsi - df.last_rsi\n",
    "    df.loc[:, 'last_rsi_roc'] = df.rsi_roc.shift(1)\n",
    "    bool_index = (df.rsi <= rsi_oversold)\n",
    "    bool_index &= (df.rsi_roc > df.last_rsi_roc)\n",
    "    bool_index &= (df.roc > roc_change)\n",
    "    bool_index &= (df.close_adj > df.mv_avg)\n",
    "    #bool_index &= (df.regime_roc > regime_roc_change)\n",
    "    bool_index &= (df.regime_close > df.regime_ma)\n",
    "    #bool_index &= (df.sector_roc > regime_roc_change)\n",
    "    bool_index &= (df.sector_close > df.sector_ma)\n",
    "    df.loc[bool_index, 'rsi_oversold_enter'] = 1\n",
    "    enter_cols = ['rsi_oversold_enter']\n",
    "    df.loc[:, 'entrances'] = df[enter_cols].sum(axis=1).clip(upper=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exits(df, rsi_overbought=70):\n",
    "    df.loc[:, 'rsi_overbought_exit'] = 0\n",
    "    bool_index = df.rsi >= rsi_overbought\n",
    "    df.loc[bool_index, 'rsi_overbought_exit'] = 1\n",
    "    exit_cols = ['rsi_overbought_exit']\n",
    "    df.loc[:, 'exits'] = df[exit_cols].sum(axis=1).clip(upper=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enter_exit = df_ind.groupby('symbol').apply(lambda x: get_entrances(get_exits(x), roc_change=10, regime_roc_change=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "def backtest_seq(df, stop_thresh=0.1, run_length=30, inv_price=10000,\n",
    "                 prof_avg_offset=30, ewm_prof_offset=100, mv_avg=None, equity=None,\n",
    "                 pickup_dt=dt.datetime(1990, 10, 18), mv_avg_ratio_thresh=.97):\n",
    "    if mv_avg is None or equity is None:\n",
    "        mv_avg = np.zeros(df.shape[0])\n",
    "        equity = np.zeros(df.shape[0])\n",
    "    df.loc[:, 'enter_exit_sig'] = df.entrances - df.exits\n",
    "    df.loc[:, 'next_open'] = df.open_adj.shift(-1)\n",
    "    profit, exit_profit, exit_index, actual_enter_exit, shares_arr, equity = backtest_numba(\n",
    "        df.enter_exit_sig.values, df.close_adj.values,\n",
    "        df.next_open.values, df.index.values, stop_thresh, run_length,\n",
    "        inv_price, equity / mv_avg, (df['date'] >= pickup_dt).values,\n",
    "        mv_avg_ratio_thresh\n",
    "    )\n",
    "    df.loc[:, 'profit'] = profit\n",
    "    df.loc[:, 'exit_profit'] = exit_profit\n",
    "    df.loc[:, 'cum_exit_profit'] = df.exit_profit.fillna(0).cumsum()\n",
    "    df.loc[:, 'equity_curve'] = equity + df.cum_exit_profit\n",
    "    bool_index = exit_index != -1\n",
    "    df.loc[bool_index, 'exit_date'] = df.loc[exit_index[bool_index], 'date'].values\n",
    "    df.loc[:, 'cum_profit'] = df.profit.fillna(0).cumsum()\n",
    "    df.loc[:, 'purch_shares'] = shares_arr\n",
    "    df.loc[:, 'norm_profit'] = profit / (df.next_open * shares_arr)\n",
    "    df.loc[df.profit == 0, 'norm_profit'] = np.nan\n",
    "    df.loc[:, 'avg_profit'] = df.norm_profit.rolling(prof_avg_offset, min_periods=1).mean()\n",
    "    df.loc[:, 'avg_profit_std'] = df.norm_profit.rolling(prof_avg_offset, min_periods=1).std()\n",
    "    df.loc[:, 'eavg_profit'] = df.avg_profit.ewm(ewm_prof_offset, ignore_na=True).mean()\n",
    "    df.loc[:, 'avg_profit'] = df.avg_profit.fillna(0)\n",
    "    df.loc[:, 'actual_enter_exit'] = actual_enter_exit\n",
    "    df.loc[:, 'actual_enter'] = 0\n",
    "    df.loc[:, 'actual_exit'] = 0\n",
    "    df.loc[df.actual_enter_exit == 1, 'actual_enter'] = 1\n",
    "    df.loc[df.actual_enter_exit == -1, 'actual_exit'] = 1\n",
    "    df.loc[:, 'trade_count'] = df.actual_enter_exit.rolling(prof_avg_offset).sum()\n",
    "    return df\n",
    "    \n",
    "\n",
    "#@jit(nopython=True)\n",
    "def backtest_numba(enter_exit, close_price, open_price, df_index, stop_thresh,\n",
    "                   run_length, inv_price, equity_signal, bool_date, mv_avg_ratio_thresh):\n",
    "    in_trade = False\n",
    "    n = len(enter_exit)\n",
    "    actual_enter_exit = np.zeros(n)\n",
    "    shares_arr = np.zeros(n)\n",
    "    equity = np.zeros(n)\n",
    "    profit = np.zeros(n)\n",
    "    exit_profit = np.zeros(n)\n",
    "    exit_index = np.zeros(n) - 1\n",
    "    start_price = 0.0\n",
    "    enter_price = 0.0\n",
    "    top_price = start_price\n",
    "    shares = 0\n",
    "    for index in range(0, n):\n",
    "        signal = enter_exit[index]\n",
    "        equity_stop_signal = equity_signal[index] < mv_avg_ratio_thresh and bool_date[index] == True\n",
    "        if in_trade and close_price[index] > top_price:\n",
    "            top_price = close_price[index]\n",
    "        if not in_trade and signal == 1 and not equity_stop_signal:\n",
    "            enter_price = open_price[index]\n",
    "            start_price = close_price[index]\n",
    "            top_price = start_price\n",
    "            shares = int(inv_price / start_price) #need condition here to see if you can afford shares\n",
    "            shares_arr[index] = shares\n",
    "            shares_cost = enter_price * shares\n",
    "            actual_enter_exit[index] = 1\n",
    "            in_trade = True\n",
    "            enter_index = index\n",
    "        elif in_trade and ((signal == -1) or ((index - enter_index) >= run_length) or equity_stop_signal): #exit signal\n",
    "            profit[enter_index] = (open_price[index] - enter_price) * shares\n",
    "            exit_profit[index] = profit[enter_index]\n",
    "            exit_index[enter_index] = df_index[index]\n",
    "            actual_enter_exit[index] = -1\n",
    "            in_trade = False\n",
    "            shares = 0\n",
    "        elif in_trade and ((top_price - close_price[index]) / top_price) >= stop_thresh: \n",
    "            profit[enter_index] = (open_price[index] - enter_price) * shares\n",
    "            exit_profit[index] = profit[enter_index]\n",
    "            exit_index[enter_index] = df_index[index]\n",
    "            actual_enter_exit[index] = -1\n",
    "            in_trade = False\n",
    "            shares = 0\n",
    "        elif index == (n - 1) and in_trade:\n",
    "            profit[enter_index] = (open_price[index] - enter_price) * shares\n",
    "            exit_profit[index] = profit[enter_index]\n",
    "            exit_index[enter_index] = df_index[index]\n",
    "            actual_enter_exit[index] = -1\n",
    "            in_trade = False\n",
    "            shares = 0 # lots of duplication here\n",
    "        equity[index] = (shares * close_price[index]) - (shares * enter_price)\n",
    "        shares_arr[index] = shares\n",
    "    return profit, exit_profit, exit_index, actual_enter_exit, shares_arr, equity # don't really need exit profit here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K28120\\py36\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "df_profits1 = df_enter_exit.groupby('symbol').apply(lambda x: backtest_seq(x, stop_thresh=1.0, inv_price=10000, run_length=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equity_adjustment(df):\n",
    "    strategy_stats_df = pd.DataFrame({'date': df['date'].unique()}).sort_values('date')\n",
    "    date_equity = df.groupby('date').equity_curve.sum().reset_index('date')\n",
    "    strategy_stats_df = strategy_stats_df.merge(date_equity, on='date', how='left')\n",
    "    strategy_stats_df.loc[:, 'equity_curve_mv_avg'] = strategy_stats_df.set_index('date').equity_curve.rolling('200d', min_periods=1)\\\n",
    "                                                                       .mean().fillna(method='ffill').values\n",
    "    strategy_stats_df.loc[:, 'equity_curve_agg'] = strategy_stats_df. equity_curve\n",
    "    return strategy_stats_df#strategy_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = 'RSIROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_adj_df = equity_adjustment(df_profits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_adj_df.to_parquet('equity_curves/%s1.parquet' % strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1_mrg = df_profits1.merge(equity_adj_df[['date', 'equity_curve_mv_avg', 'equity_curve_agg']], on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1_mrg.to_parquet('profits/%s.parquet' % strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits2 = df_profits1_mrg.groupby('symbol').apply(lambda x: backtest_seq(x, stop_thresh=1.0, inv_price=10000, run_length=run_length,\n",
    "                                                                             mv_avg=x.equity_curve_mv_avg.values, equity=x.equity_curve_agg.values,\n",
    "                                                                             pickup_dt=df_profits1_mrg['date'].min() + dt.timedelta(days=400),\n",
    "                                                                             mv_avg_ratio_thresh=.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_adj_df = equity_adjustment(df_profits2)\n",
    "equity_adj_df.to_parquet('equity_curves/%s2.parquet' % strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_profit_metrics(df_profits):\n",
    "    wins_losses = {}\n",
    "    col_name = 'profit'\n",
    "    win_index = df_profits[col_name] > 0\n",
    "    loss_index = df_profits[col_name] < 0\n",
    "    mean_win = df_profits.loc[win_index, col_name].mean()\n",
    "    mean_loss = df_profits.loc[loss_index, col_name].mean()\n",
    "    mean_norm_profit_win = df_profits.loc[win_index, 'norm_profit'].mean()\n",
    "    mean_norm_profit_loss = df_profits.loc[loss_index, 'norm_profit'].mean()\n",
    "    mean_norm_profit = df_profits.norm_profit.mean()\n",
    "    sum_win = df_profits.loc[win_index, col_name].sum()\n",
    "    sum_loss = df_profits.loc[loss_index, col_name].sum()\n",
    "    \n",
    "    wins_losses[col_name] = [win_index.sum(), loss_index.sum(), win_index.sum() + loss_index.sum(),\n",
    "                             mean_win, mean_loss,\n",
    "                             mean_norm_profit_win, mean_norm_profit_loss,\n",
    "                             mean_norm_profit,\n",
    "                             sum_win, sum_loss\n",
    "                            ]\n",
    "\n",
    "    df_win_loss = pd.DataFrame(wins_losses, index=['wins', 'losses', 'ttl_trades', 'mean_win',\n",
    "                                                   'mean_loss',\n",
    "                                                   'mean_norm_profit_win', 'mean_norm_profit_loss',\n",
    "                                                   'mean_norm_profit',\n",
    "                                                   'ttl_win', 'ttl_loss']).transpose()\n",
    "    df_win_loss.loc[:, 'win_loss_rate'] =  df_win_loss.wins / (df_win_loss.losses + df_win_loss.wins)\n",
    "    df_win_loss.loc[:, 'win_loss_ratio'] = df_win_loss.mean_win / np.abs(df_win_loss.mean_loss)\n",
    "    \n",
    "    df_win_loss.loc[:, 'profit_factor'] = df_win_loss.ttl_win / np.abs(df_win_loss.ttl_loss)\n",
    "    df_win_loss.loc[:, 'net_profit'] = df_win_loss.ttl_win + df_win_loss.ttl_loss\n",
    "    return df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_days = df_profits1['date'].unique().shape[0]\n",
    "sig_days = df_profits1.loc[df_profits1.entrances == 1, 'date'].unique().shape[0]\n",
    "sig_days / ttl_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss = get_profit_metrics(df_profits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1.loc[:, 'month'] = df_profits1['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss_year = df_profits1.groupby('year').apply(get_profit_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss_year_month_sym = df_profits1.groupby(['symbol', 'year', 'month']).agg({'profit': 'sum'})\n",
    "df_win_loss_year_month_sym = df_win_loss_year_month_sym.loc[df_win_loss_year_month_sym.profit != 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_2018 = df_win_loss_year_month_sym.loc[df_win_loss_year_month_sym.year == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_2018.groupby('month').profit.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_2018.loc[prof_2018.month == 1].sort_values('profit', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_loss_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = 'RSIROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_adj_df = equity_adjustment(df_profits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_adj_df.to_parquet('equity_curves/%s.parquet' % strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1 = df_profits1.merge(equity_adj_df[['date', 'cum_prof', 'cum_prof_mv_avg', 'strategy_on']], on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profits1.to_parquet('profits/%s.parquet' % strategy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements \n",
    "* Look for price increase after reversion based indicators - V1\n",
    "* Weight examples in XGBoost by Price. Look at training vs testing profit - V2\n",
    "* Add Bollinger band based indicator - V3\n",
    "* Add Regime Filter - V4\n",
    "* Use Symbol Performance based filtering - V5\n",
    "* Look at performance across Industry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
