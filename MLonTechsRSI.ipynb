{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_dir = 'profits'\n",
    "strategy_files = os.listdir(base_dir)\n",
    "strategy_names = [x.split('.')[0] for x in strategy_files]\n",
    "strategy_results = {x: pd.read_parquet('%s/%s.parquet' % (base_dir, x)) for x in strategy_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['symbol', 'date', 'open_adj', 'high_adj', 'low_adj',\n",
    "        'close_adj', 'actual_enter', 'entrances', 'exits',\n",
    "        'trade_count', 'next_open', 'profit', 'norm_profit',\n",
    "        'avg_profit', 'avg_profit_std', 'eavg_profit', 'volume',\n",
    "        'mv_avg', 'sector',  'regime_close', 'regime_ma', 'sector_close', 'sector_ma'] + strategy_names\n",
    "for strategy in strategy_names:\n",
    "    df = strategy_results[strategy]\n",
    "    for strategy2 in strategy_names:\n",
    "        df.loc[:, strategy2] = 0 if strategy != strategy2 else 1\n",
    "    strategy_results[strategy] = df[cols].drop_duplicates(subset=['symbol', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_df = pd.concat((strategy_results[x] for x in strategy_results), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little exploratory analysis of signal frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_df = strategy_df.loc[strategy_df.actual_enter == 1]\n",
    "sig_df = sig_df.dropna(subset=['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_count = sig_df.groupby('date').agg({'close_adj': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### profit correlation analysis original feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sig_df.loc[:, 'sig_count'] = sig_df['date'].map(day_count.close_adj)\n",
    "for ind, col in enumerate(strategy_names):\n",
    "    plt.figure(ind)\n",
    "    df = sig_df.loc[sig_df[col] == 1]\n",
    "    df.groupby('sig_count').agg({'norm_profit': 'mean'}).reset_index().plot(x='sig_count', y='norm_profit', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
    "\n",
    "sig_df.loc[:, 'sig_count'] = sig_df['date'].map(day_count.close_adj)\n",
    "for ind, col in enumerate(strategy_names):\n",
    "    df = sig_df.loc[sig_df[col] == 1]\n",
    "    df.loc[:, 'avg_profit'] = df.avg_profit.shift(1)\n",
    "    df = df.dropna()\n",
    "    fig.add_trace(\n",
    "        go.Histogram2d(x=df.avg_profit, y=df.norm_profit, histnorm='probability', name=col),\n",
    "        row=(ind + 1), col=1\n",
    "    )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as disp\n",
    "for ind, col in enumerate(['MFIROC', 'RSIROC', 'STO']):\n",
    "    df = sig_df.loc[(sig_df[col] == 1) & (sig_df.avg_profit != 0)]\n",
    "    df.loc[:, 'avg_profit'] = df.avg_profit.shift(1)\n",
    "    df = df.dropna()\n",
    "    disp.display(df[['avg_profit', 'norm_profit', 'eavg_profit', 'sig_count']].corr('spearman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_ind_cols = ['symbol', 'date', 'open_adj', 'high_adj', 'low_adj', 'close_adj', 'volume',\n",
    "                 'mv_avg', 'sector', 'regime_close', 'regime_ma', 'sector_close', 'sector_ma']\n",
    "candle_data = strategy_df[tech_ind_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "import numpy as np\n",
    "\n",
    "def mean_atr(df, atr_period=14):\n",
    "    df.loc[:, 'last_close'] = df.close_adj.shift(1)\n",
    "    atr_high = np.maximum(df.high_adj, df.last_close)\n",
    "    atr_low = np.minimum(df.high_adj, df.last_close)\n",
    "    atr = atr_high - atr_low\n",
    "    return atr, atr.ewm(span=atr_period, adjust=False).mean()\n",
    "\n",
    "def mean_close_diff_norm(close, ma):\n",
    "    return (close - ma) / ma\n",
    "\n",
    "def generate_ta_features(sym_df, rsi_period=5, roc_period=45, fut_roc_period=5, mfi_period=5,\n",
    "                         sto_period=14, atr_period=14, bba_period=20,\n",
    "                         dch_period=20):\n",
    "    sym_df = sym_df.sort_values('date')\n",
    "    rsi = ta.momentum.RSIIndicator(close=sym_df.close_adj, n=rsi_period).rsi()\n",
    "    roc = ta.momentum.ROCIndicator(sym_df.close_adj, n=roc_period).roc()\n",
    "    roc_fut = ta.momentum.ROCIndicator(sym_df.close_adj, n=fut_roc_period).roc()\n",
    "    mfi = ta.momentum.MFIIndicator(\n",
    "        high=sym_df.high_adj, low=sym_df.low_adj,\n",
    "        close=sym_df.close_adj, volume=sym_df.volume,\n",
    "        n=mfi_period\n",
    "    ).money_flow_index()\n",
    "    sto = ta.momentum.StochIndicator(high=sym_df.high_adj, low=sym_df.low_adj, close=sym_df.close_adj,\n",
    "                                     n=sto_period).stoch_signal()\n",
    "    atr, mean_atr_var = mean_atr(sym_df, atr_period=atr_period)\n",
    "    bb = ta.volatility.BollingerBands(close=sym_df.close_adj, n=bba_period)\n",
    "    bb_high = bb.bollinger_hband()\n",
    "    bb_low = bb.bollinger_lband()\n",
    "    bba = bb_high - bb_low\n",
    "    dc = ta.volatility.DonchianChannel(close=sym_df.close_adj, n=dch_period)\n",
    "    dc_high = dc.donchian_channel_hband()\n",
    "    dc_low = dc.donchian_channel_lband()\n",
    "    dch = dc_high - dc_low\n",
    "    sym_df.loc[:, 'rsi'] = rsi\n",
    "    sym_df.loc[:, 'roc'] = roc\n",
    "    sym_df.loc[:, 'fut_roc'] = roc_fut.shift(-fut_roc_period)\n",
    "    sym_df.loc[:, 'mfi'] = mfi\n",
    "    sym_df.loc[:, 'sto'] = sto\n",
    "    sym_df.loc[:, 'atr'] = atr\n",
    "    sym_df.loc[:, 'atr_norm'] = atr / sym_df.close_adj\n",
    "    sym_df.loc[:, 'mean_atr'] = mean_atr_var\n",
    "    sym_df.loc[:, 'mean_atr_norm'] = mean_atr_var / sym_df.close_adj\n",
    "    sym_df.loc[:, 'bba'] = bba\n",
    "    sym_df.loc[:, 'dch'] = dch\n",
    "    sym_df.loc[:, 'bba_norm'] = bba / sym_df.close_adj\n",
    "    sym_df.loc[:, 'dch_norm'] = dch / sym_df.close_adj\n",
    "    sym_df.loc[:, 'ma_diff_norm'] = mean_close_diff_norm(sym_df.close_adj, sym_df.mv_avg)\n",
    "    sym_df.loc[:, 'regime_ma_diff_norm'] = mean_close_diff_norm(sym_df.regime_close, sym_df.regime_ma)\n",
    "    sym_df.loc[:, 'sector_ma_diff_norm'] = mean_close_diff_norm(sym_df.sector_close, sym_df.sector_ma)\n",
    "    sym_df.loc[:, 'volatility'] = (sym_df.close_adj.diff() / sym_df.close_adj.shift(1)).abs().ewm(span=atr_period,\n",
    "                                                                                                  adjust=False).mean()\n",
    "    sym_df.loc[:, 'bar_range'] = (sym_df.close_adj - sym_df.low_adj) / (sym_df.high_adj - sym_df.low_adj)\n",
    "    ta_cols = ['symbol', 'date', 'rsi', 'roc', 'mfi', 'sto', 'atr', 'mean_atr', 'bba', 'dch', 'fut_roc',\n",
    "               'ma_diff_norm', 'regime_ma_diff_norm', 'sector_ma_diff_norm', 'volatility', 'bar_range', 'mean_atr_norm',\n",
    "               'bba_norm', 'dch_norm'\n",
    "               ]\n",
    "    return sym_df[ta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1261/1261 [01:54<00:00, 11.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "ta_feats = candle_data.groupby('symbol').progress_apply(lambda x: generate_ta_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = strategy_df.merge(ta_feats.reset_index(drop=True), on=['symbol', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag_feats(sym_df, sharp_period=100):\n",
    "    sym_df = sym_df.sort_values('date')\n",
    "    sym_df.loc[:, 'lag_eavg_profit'] = sym_df.eavg_profit.shift(1)\n",
    "    sym_df.loc[:, 'lag_avg_profit'] = sym_df.avg_profit.shift(1)\n",
    "    sym_df.loc[:, 'lag_avg_profit_std'] = sym_df.avg_profit_std.shift(1)\n",
    "    sym_df.loc[:, 'lag_eavg_profit_std'] = sym_df.lag_eavg_profit.rolling(sharp_period).std()\n",
    "    sym_df.loc[:, 'sharp_ratio'] = sym_df.lag_eavg_profit / sym_df.lag_eavg_profit_std\n",
    "    lag_cols = ['date', 'symbol', 'strategy_ind', 'lag_eavg_profit', 'lag_avg_profit',\n",
    "                'lag_eavg_profit_std', 'sharp_ratio']\n",
    "    return sym_df[lag_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "strat_w = np.array([[-1, 0, 1, 2]])\n",
    "feat_df.loc[:, 'strategy_ind'] = (feat_df[strategy_names] * strat_w).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5044/5044 [01:29<00:00, 56.23it/s]\n"
     ]
    }
   ],
   "source": [
    "lag_feats = feat_df.groupby(['symbol', 'strategy_ind']).progress_apply(lambda x: get_lag_feats(x, sharp_period=45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feat_df.merge(lag_feats.reset_index(drop=True), on=['date', 'symbol', 'strategy_ind'])\n",
    "feature_df.loc[:, 'sig_count'] = feature_df['date'].map(day_count.close_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation analysis with profit and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sig_df = feature_df.loc[feature_df.actual_enter == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sig_df.loc[:, 'sig_count'] = feat_sig_df['date'].map(day_count.close_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col = ['rsi', 'roc', 'mfi', 'sto', 'bba', 'dch', 'lag_eavg_profit',\n",
    "            'sig_count', 'lag_eavg_profit_std', 'lag_avg_profit', 'sector_ma_diff_norm',\n",
    "            'volatility',\n",
    "            ] # left out lag_avg_profit , 'ma_diff_norm', 'sector_ma_diff_norm','regime_ma_diff_norm'\n",
    "target_col = ['norm_profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "feat_sig_df[feat_col + target_col].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_df[['lag_eavg_profit', 'lag_eavg_profit_std', 'sharp_ratio']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.loc[feature_df.symbol == 'XOM'][['lag_eavg_profit', 'lag_eavg_profit_std', 'sharp_ratio']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def get_ml_data(feature_df, feat_col, strategy_names, min_sig_cnt=2,\n",
    "                train_date_range=(dt.datetime(2000, 1, 1), dt.datetime(2001, 12, 31)),\n",
    "                test_date_range=(dt.datetime(2002, 1, 1), dt.datetime(2018, 1, 1))):\n",
    "    notnull_index = (feature_df.norm_profit.notnull()) & (feature_df.sig_count > min_sig_cnt)\n",
    "    aux_cols = ['date', 'norm_profit', 'symbol']\n",
    "    feats = feature_df.loc[notnull_index, feat_col + strategy_names + aux_cols]\\\n",
    "                      .sort_values('date')\n",
    "    all_data = feature_df.loc[:, feat_col + strategy_names + ['actual_enter']]\n",
    "    all_aux = feature_df.loc[:, aux_cols]\n",
    "    norm_profits = feats.norm_profit\n",
    "    target = (norm_profits > 0).astype(int)\n",
    "    groups = (feats['date'] - dt.datetime(1970, 1 , 1)).apply(lambda x: x.days)\n",
    "    train_index = feats['date'].between(*train_date_range).values\n",
    "    test_index = feats['date'].between(*test_date_range).values\n",
    "    train_aux = feats.loc[train_index, aux_cols]\n",
    "    test_aux = feats.loc[test_index, aux_cols]\n",
    "    feats = feats[feat_col + strategy_names]\n",
    "    train_x = feats.loc[train_index]\n",
    "    train_y = target.loc[train_index]\n",
    "    train_groups = groups.loc[train_index]\n",
    "    train_group_size = train_groups.value_counts().sort_index().values\n",
    "    test_x = feats.loc[test_index]\n",
    "    test_y = target.loc[test_index]\n",
    "    test_groups = groups.loc[test_index]\n",
    "    test_group_size = test_groups.value_counts().sort_index().values\n",
    "    data_dict = {\n",
    "        'train_x': train_x, 'train_y': train_y,\n",
    "        'train_groups': train_groups, 'train_group_size': train_group_size,\n",
    "        'test_x': test_x, 'test_y': test_y,\n",
    "        'test_groups': test_groups, 'test_group_size': test_group_size,\n",
    "        'train_aux': train_aux,\n",
    "        'test_aux': test_aux,\n",
    "        'all_data': all_data,\n",
    "        'all_aux': all_aux,\n",
    "        'ml_cols': feat_col + strategy_names\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'date', 'open_adj', 'high_adj', 'low_adj', 'close_adj',\n",
       "       'actual_enter', 'entrances', 'exits', 'trade_count', 'next_open',\n",
       "       'profit', 'norm_profit', 'avg_profit', 'avg_profit_std', 'eavg_profit',\n",
       "       'volume', 'mv_avg', 'sector', 'regime_close', 'regime_ma',\n",
       "       'sector_close', 'sector_ma', 'MFIROC', 'MFIROCLong', 'RSIROC', 'STO',\n",
       "       'rsi', 'roc', 'mfi', 'sto', 'atr', 'mean_atr', 'bba', 'dch', 'fut_roc',\n",
       "       'ma_diff_norm', 'regime_ma_diff_norm', 'sector_ma_diff_norm',\n",
       "       'volatility', 'bar_range', 'mean_atr_norm', 'bba_norm', 'dch_norm',\n",
       "       'strategy_ind', 'lag_eavg_profit', 'lag_avg_profit',\n",
       "       'lag_eavg_profit_std', 'sharp_ratio', 'sig_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_ml_data(feature_df, feat_col, strategy_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=5, n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb_clf.fit(\n",
    "    data_dict['train_x'], data_dict['train_y'],\n",
    "    sample_weight=np.abs(data_dict['train_aux']['norm_profit']),\n",
    "    eval_set=[(data_dict['train_x'], data_dict['train_y']),\n",
    "              (data_dict['test_x'], data_dict['test_y'])],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5510143296819672"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=5, class_weight='balanced')\n",
    "rfc = rfc.fit(data_dict['train_x'].fillna(0), data_dict['train_y'], sample_weight=np.abs(data_dict['train_aux']['norm_profit']))\n",
    "1- rfc.score(data_dict['test_x'].fillna(0), data_dict['test_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_clf.predict(data_dict['test_x'], output_margin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rfc.predict_proba(data_dict['test_x'].fillna(0))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rfc.predict_proba(data_dict['train_x'].fillna(0))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = xgb_clf.predict(data_dict['all_data'], output_margin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = rfc.predict_proba(data_dict['all_data'][data_dict['ml_cols']].fillna(0))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data_dict['all_data']\n",
    "all_data_entries = all_data.loc[all_data.actual_enter == 1, data_dict['ml_cols']]\n",
    "all_preds = rfc.predict_proba(all_data_entries.fillna(0))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_norm = pd.read_parquet('historical_pr_data_600_sec.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr = data_dict['train_x'].copy()\n",
    "eval_tr.loc[:, 'preds'] = preds\n",
    "for aux_col in ['date', 'norm_profit', 'symbol']:\n",
    "    eval_tr.loc[:, aux_col] = data_dict['train_aux'][aux_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr = data_dict['test_x'].copy()\n",
    "eval_tr.loc[:, 'preds'] = preds\n",
    "for aux_col in ['date', 'norm_profit', 'symbol']:\n",
    "    eval_tr.loc[:, aux_col] = data_dict['test_aux'][aux_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr = data_dict['all_data'].copy()\n",
    "#eval_tr.loc[eval_tr.actual_enter == 1, 'preds'] = all_preds\n",
    "eval_tr.loc[:, 'preds'] = all_preds\n",
    "for aux_col in ['date', 'norm_profit', 'symbol']:\n",
    "    eval_tr.loc[:, aux_col] = data_dict['all_aux'][aux_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr = data_dict['all_data'].copy()\n",
    "eval_tr.loc[eval_tr.actual_enter == 1, 'preds'] = all_preds\n",
    "#eval_tr.loc[:, 'preds'] = all_preds\n",
    "for aux_col in ['date', 'norm_profit', 'symbol']:\n",
    "    eval_tr.loc[:, aux_col] = data_dict['all_aux'][aux_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_backtest_df(pred_df, feature_df):\n",
    "    feature_df.loc[:, 'pred_score'] = pred_df.preds.values\n",
    "    return feature_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df = make_backtest_df(eval_tr, feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df.loc[backtest_df['date'] >= dt.datetime(2002, 1, 1)].to_parquet('backtesting/small_mid_lrg_cap_signals.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = backtest_df.loc[backtest_df['date'] >= dt.datetime(2002, 1, 1)]\n",
    "time_df.loc[(time_df.actual_enter == 1) | (time_df.exits == 1)].to_parquet('backtesting/small_mid_lrg_cap_signals.parquet')\n",
    "time_df[['date']].drop_duplicates().sort_values('date').to_parquet('backtesting/small_mid_lrg_cap_dt_rng.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df.loc[(backtest_df['date'] >= dt.datetime(2011, 1, 1)) & (backtest_df['norm_profit'] != 0) & (backtest_df['sig_count'] > 1)][['pred_score', 'norm_profit']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr[['preds', 'norm_profit']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scattergl(x=eval_tr.preds, y=eval_tr.norm_profit, mode='markers')\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr.sort_values('preds', ascending=False).to_excel('XGBoostExamine.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr[['preds', 'norm_profit']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr.plot('preds', 'norm_profit', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr[['preds', 'norm_profit']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def select_signals_rand(df):\n",
    "    indices = np.random.choice(df.shape[0], size=2, replace=False)\n",
    "    return df.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monte carlo simulation\n",
    "import progressbar\n",
    "runs = 5\n",
    "rand_prof = []\n",
    "for sim in progressbar.progressbar(range(runs)):\n",
    "    selected_rand_train = eval_tr.groupby('date').apply(select_signals_rand)\n",
    "    rand_prof.append(selected_rand_train.norm_profit.mean())\n",
    "np.mean(rand_prof), np.std(rand_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_signals(df):\n",
    "    #df = df.loc[df.preds >= 0.5]\n",
    "    df = df.sort_values('preds', ascending=False)\n",
    "    #df = df.sort_values('volatility', ascending=False)\n",
    "    df.drop_duplicates( subset=['symbol'], keep='first')\n",
    "    return df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection = eval_tr.groupby('date').apply(select_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = pd.read_parquet('backtesting/actual_entries.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries[['date', 'symbol']].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "best_selection[['symbol']].loc[dt.datetime(2011, 1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries.drop_duplicates(subset=['symbol'], keep='first').iloc[:40].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection.norm_profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tr.loc[eval_tr.preds > 0.3]['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "sym_df = eval_tr.loc[(eval_tr.MFIROC==1) & (eval_tr.symbol=='A')]\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=sym_df.date, y=sym_df.norm_profit, name='norm profit', mode='markers+lines')\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=sym_df.date, y=sym_df.lag_eavg_profit, name='eprof', mode='markers+lines')\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "eval_tr.columns[np.argsort(rfc.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(xgb_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead ROC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import seaborn\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "sub_df = feature_df.loc[feature_df['date'] >= dt.datetime(2014, 1, 1)][feat_col[:4] + ['fut_roc']]\n",
    "indices = list(range(sub_df.shape[0]))\n",
    "random.shuffle(indices)\n",
    "sub_df = sub_df.iloc[indices[:100000]]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scattergl(x=sub_df.rsi, y=sub_df.fut_roc, mode='markers')\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import seaborn\n",
    "import random\n",
    "sub_df = feature_df.loc[feature_df['date'] >= dt.datetime(2014, 1, 1)][feat_col[:4] + ['fut_roc']]\n",
    "indices = list(range(sub_df.shape[0]))\n",
    "random.shuffle(indices)\n",
    "sub_df = sub_df.iloc[indices[:100000]]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scattergl(x=sub_df.sto, y=sub_df.fut_roc, mode='markers')\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
